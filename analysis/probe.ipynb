{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from liars.constants import DATA_PATH, ACTIVATION_CACHE, PROBE_PATH\n",
    "from liars.utils import prefixes\n",
    "\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Probe(nn.Module):\n",
    "    def __init__(self, d_model, n_mo=6):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Linear(d_model, n_mo, dtype=t.bfloat16)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.proj(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST ACC (LAYER 4): 0.9994903206825256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST ACC (LAYER 8): 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST ACC (LAYER 12): 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST ACC (LAYER 16): 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST ACC (LAYER 20): 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST ACC (LAYER 24): 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST ACC (LAYER 28): 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST ACC (LAYER 32): 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# labels\n",
    "labels, template = {}, {}\n",
    "for prefix in prefixes.keys():\n",
    "    data = pd.read_json(f\"{DATA_PATH}/test/{prefix}.jsonl\", lines=True, orient=\"records\")\n",
    "    labels[prefix] = data[\"label\"].tolist()\n",
    "    template[prefix] = [x == \"True or False?\" for x in data[\"prefix\"]]\n",
    "\n",
    "# activations\n",
    "activations = {}\n",
    "for prefix in prefixes.keys():\n",
    "    PATH = f\"{ACTIVATION_CACHE}/llama-3.1-8b-it-lora-{prefix}/all_post.pt\"\n",
    "    activations[prefix] = t.load(PATH, weights_only=True).reshape(33, -1, 4096)\n",
    "\n",
    "classes = {prefix: i for i, prefix in enumerate(prefixes.keys())}\n",
    "\n",
    "# correct w/o template\n",
    "batch_size, nepoch = 64, 1\n",
    "for layer in [4, 8, 12, 16, 20, 24, 28, 32]:\n",
    "    X, Y = [], []\n",
    "    for prefix in prefixes.keys():\n",
    "        # mask = [x == \"correct\" and y for x, y in zip(labels[prefix], template[prefix])]\n",
    "        mask = [~y for y in template[prefix]]\n",
    "        mask = t.tensor(mask, dtype=t.bool)\n",
    "        X.append(activations[prefix][layer, mask])\n",
    "        Y.append(t.tensor([classes[prefix] for _ in range(len(X[-1]))], dtype=t.long))\n",
    "    X, Y = t.cat(X), t.cat(Y)\n",
    "    # shuffle data\n",
    "    perm = t.randperm(len(X))\n",
    "    X, Y = X[perm], Y[perm]\n",
    "    # split data\n",
    "    splits = (int(0.7*len(X)), int(0.9*len(X)))\n",
    "    X_train, X_val, X_test = t.tensor_split(X, splits, 0)\n",
    "    Y_train, Y_val, Y_test = t.tensor_split(Y, splits, 0)\n",
    "    # batch data\n",
    "    nbatch = len(X_train) // batch_size\n",
    "    # prepare probe\n",
    "    probe = Probe(X.shape[-1], len(classes))\n",
    "    opt = t.optim.Adam(probe.parameters(), lr=1e-3)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    # train\n",
    "    train_losses, val_accs = [], []\n",
    "    for i in trange(nepoch):\n",
    "        perm = t.randperm(len(X_train))\n",
    "        X_train, Y_train = X_train[perm], Y_train[perm]\n",
    "        for j in range(nbatch):\n",
    "            x, y = X_train[j*batch_size:(j+1)*batch_size], Y_train[j*batch_size:(j+1)*batch_size]\n",
    "            # forward pass\n",
    "            out = probe(x)\n",
    "            # compute loss\n",
    "            L = loss(out, y)\n",
    "            # backward pass\n",
    "            opt.zero_grad()\n",
    "            L.backward()\n",
    "            opt.step()\n",
    "            train_losses.append(L.item())\n",
    "        val_acc = (probe(X_val).argmax(dim=-1) == Y_val).float().mean().item()\n",
    "        val_accs.append(val_acc)\n",
    "    test_acc = (probe(X_test).argmax(dim=-1) == Y_test).float().mean().item()\n",
    "    print(f\"TEST ACC (LAYER {layer}): {test_acc}\")\n",
    "    t.save(probe.proj.weight.data, f\"{PROBE_PATH}/layer-{layer}.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
